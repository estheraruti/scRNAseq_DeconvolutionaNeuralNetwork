{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconvolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes how the DCNN was built and trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single-cell or bulk-sorted RNA sequencing data can be used to learn molecular signatures of distinct cell types from a small collection of biospecimens. These signatures can then be repeatedly applied to characterize cellular heterogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2DTranspose, Conv2D\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File / Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing UCD single cell test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 2700 × 32738\n",
      "    var: 'gene_ids'\n",
      "Viewing first five rows\n",
      "  (0, 70)\t1.0\n",
      "  (0, 166)\t1.0\n",
      "  (0, 178)\t2.0\n",
      "  (0, 326)\t1.0\n",
      "  (0, 363)\t1.0\n",
      "  (0, 410)\t1.0\n",
      "  (0, 412)\t1.0\n",
      "  (0, 492)\t41.0\n",
      "  (0, 494)\t1.0\n",
      "  (0, 495)\t1.0\n",
      "  (0, 496)\t1.0\n",
      "  (0, 525)\t1.0\n",
      "  (0, 556)\t2.0\n",
      "  (0, 558)\t6.0\n",
      "  (0, 671)\t1.0\n",
      "  (0, 684)\t1.0\n",
      "  (0, 735)\t1.0\n",
      "  (0, 770)\t1.0\n",
      "  (0, 793)\t1.0\n",
      "  (0, 820)\t1.0\n",
      "  (0, 859)\t2.0\n",
      "  (0, 871)\t1.0\n",
      "  (0, 908)\t15.0\n",
      "  (0, 926)\t1.0\n",
      "  (0, 941)\t1.0\n",
      "  :\t:\n",
      "  (4, 31257)\t1.0\n",
      "  (4, 31390)\t1.0\n",
      "  (4, 31488)\t1.0\n",
      "  (4, 31493)\t1.0\n",
      "  (4, 31661)\t1.0\n",
      "  (4, 31665)\t1.0\n",
      "  (4, 31714)\t1.0\n",
      "  (4, 31728)\t1.0\n",
      "  (4, 31759)\t1.0\n",
      "  (4, 31859)\t1.0\n",
      "  (4, 31923)\t1.0\n",
      "  (4, 31945)\t2.0\n",
      "  (4, 31963)\t2.0\n",
      "  (4, 31970)\t1.0\n",
      "  (4, 32008)\t1.0\n",
      "  (4, 32022)\t3.0\n",
      "  (4, 32436)\t1.0\n",
      "  (4, 32595)\t1.0\n",
      "  (4, 32611)\t1.0\n",
      "  (4, 32645)\t2.0\n",
      "  (4, 32696)\t1.0\n",
      "  (4, 32698)\t7.0\n",
      "  (4, 32702)\t1.0\n",
      "  (4, 32706)\t2.0\n",
      "  (4, 32708)\t1.0\n",
      "View the cell annotations\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [AAACATACAACCAC-1, AAACATTGAGCTAC-1, AAACATTGATCAGC-1, AAACCGTGCTTCCG-1, AAACCGTGTATGCG-1]\n",
      "View the gene annotations\n",
      "                     gene_ids\n",
      "index                        \n",
      "MIR1302-10    ENSG00000243485\n",
      "FAM138A       ENSG00000237613\n",
      "OR4F5         ENSG00000186092\n",
      "RP11-34P13.7  ENSG00000238009\n",
      "RP11-34P13.8  ENSG00000239945\n"
     ]
    }
   ],
   "source": [
    "# Load the .h5ad file\n",
    "adata = sc.read_h5ad('pbmc3k_raw.h5ad')\n",
    "\n",
    "# Print some basic information about the AnnData object\n",
    "print(adata)\n",
    "\n",
    "# View the first few rows of the data matrix\n",
    "print(\"Viewing first five rows\")\n",
    "print(adata.X[:5])  # View the first 5 rows of the data matrix\n",
    "\n",
    "# View the observation (cell) annotations\n",
    "print(\"View the cell annotations\")\n",
    "print(adata.obs.head())\n",
    "\n",
    "# View the variable (gene) annotations\n",
    "print(\"View the gene annotations\")\n",
    "print(adata.var.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the PBMC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the datasets within the \"matrix\" group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group name: matrix\n",
      "Datasets within the group:\n",
      "barcodes\n",
      "data\n",
      "features\n",
      "indices\n",
      "indptr\n",
      "shape\n",
      "\n",
      "Dataset: barcodes\n",
      "Shape: (15554,)\n",
      "dtype: |S18\n",
      "Preview of dataset values:\n",
      "[b'AAACCCAAGCTTCGTA-1' b'AAACCCAAGGCACTCC-1' b'AAACCCACACGGCACT-1'\n",
      " b'AAACCCATCAACTGGT-1' b'AAACCCATCTACAGGT-1' b'AAACGAAGTCTGCCTT-1'\n",
      " b'AAACGAAGTCTTACTT-1' b'AAACGAAGTTAATGAG-1' b'AAACGAATCGACGAGA-1'\n",
      " b'AAACGCTCACTTCTCG-1' b'AAACGCTCATCCTAAG-1' b'AAACGCTCATGGATCT-1'\n",
      " b'AAACGCTGTCACTTCC-1' b'AAACGCTGTGCCCAGT-1' b'AAACGCTTCACTACGA-1']\n",
      "\n",
      "Dataset: data\n",
      "Shape: (58842498,)\n",
      "dtype: int32\n",
      "Preview of dataset values:\n",
      "[ 5  1  1  1  3  2  1  3  1  4  1  1  1 13  3]\n",
      "\n",
      "Dataset: indices\n",
      "Shape: (58842498,)\n",
      "dtype: int64\n",
      "Preview of dataset values:\n",
      "[ 36  51  60  64  67  69  81  88  93  94 121 152 156 180 200]\n",
      "\n",
      "Dataset: indptr\n",
      "Shape: (15555,)\n",
      "dtype: int64\n",
      "Preview of dataset values:\n",
      "[    0  3672  6671  9762 12903 14496 17012 20677 23813 26149 29929 33118\n",
      " 39367 42077 45649]\n",
      "\n",
      "Dataset: shape\n",
      "Shape: (2,)\n",
      "dtype: int32\n",
      "Preview of dataset values:\n",
      "[38616 15554]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('Human_PBMC_TotalSeqB_3p_nextgem_gemx_nobatchcorrect_count_filtered_feature_bc_matrix.h5', 'r') as f:\n",
    "    # Specify the group name\n",
    "    group_name = 'matrix'\n",
    "\n",
    "    # Access the group\n",
    "    group = f[group_name]\n",
    "\n",
    "    # Print group attributes\n",
    "    print(\"Group name:\", group_name)\n",
    "    # As it's a group, it won't have a shape attribute\n",
    "    # Add more attributes as needed\n",
    "\n",
    "    # Print the datasets within the group\n",
    "    print(\"Datasets within the group:\")\n",
    "    for dataset_name in group:\n",
    "        print(dataset_name)\n",
    "\n",
    "    # Access and inspect the datasets\n",
    "    for dataset_name in group:\n",
    "        dataset = group[dataset_name]\n",
    "        if isinstance(dataset, h5py.Dataset):\n",
    "            print(\"\\nDataset:\", dataset_name)\n",
    "            print(\"Shape:\", dataset.shape)\n",
    "            print(\"dtype:\", dataset.dtype)\n",
    "            print(\"Preview of dataset values:\")\n",
    "            print(dataset[:15])  # Print the first five rows of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the datasets within the \"features\" group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_all_tag_keys\n",
      "\n",
      "[b'genome' b'read' b'pattern' b'sequence']\n",
      "\n",
      "feature_type\n",
      "\n",
      "[b'Gene Expression' b'Gene Expression' b'Gene Expression'\n",
      " b'Gene Expression' b'Gene Expression' b'Gene Expression'\n",
      " b'Gene Expression' b'Gene Expression' b'Gene Expression'\n",
      " b'Gene Expression']\n",
      "\n",
      "genome\n",
      "\n",
      "[b'GRCh38' b'GRCh38' b'GRCh38' b'GRCh38' b'GRCh38' b'GRCh38' b'GRCh38'\n",
      " b'GRCh38' b'GRCh38' b'GRCh38']\n",
      "\n",
      "id\n",
      "\n",
      "[b'ENSG00000290825' b'ENSG00000243485' b'ENSG00000237613'\n",
      " b'ENSG00000290826' b'ENSG00000186092' b'ENSG00000238009'\n",
      " b'ENSG00000239945' b'ENSG00000239906' b'ENSG00000241860'\n",
      " b'ENSG00000241599']\n",
      "\n",
      "name\n",
      "\n",
      "[b'DDX11L2' b'MIR1302-2HG' b'FAM138A' b'ENSG00000290826' b'OR4F5'\n",
      " b'ENSG00000238009' b'ENSG00000239945' b'ENSG00000239906'\n",
      " b'ENSG00000241860' b'ENSG00000241599']\n",
      "\n",
      "pattern\n",
      "\n",
      "[b'' b'' b'' b'' b'' b'' b'' b'' b'' b'']\n",
      "\n",
      "read\n",
      "\n",
      "[b'' b'' b'' b'' b'' b'' b'' b'' b'' b'']\n",
      "\n",
      "sequence\n",
      "\n",
      "[b'' b'' b'' b'' b'' b'' b'' b'' b'' b'']\n"
     ]
    }
   ],
   "source": [
    "# Open the HDF5 file\n",
    "with h5py.File('Human_PBMC_TotalSeqB_3p_nextgem_gemx_nobatchcorrect_count_filtered_feature_bc_matrix.h5', 'r') as file:\n",
    "    # Navigate to the parent group\n",
    "    parent_group = file['matrix']\n",
    "    \n",
    "    # Navigate to the child group within the parent group\n",
    "    child_group = parent_group['features']\n",
    "    \n",
    "    # Now you can work with datasets or subgroups within the child group\n",
    "    # For example, to access a dataset within the child group:\n",
    "    for dataset_name in child_group:\n",
    "        dataset = child_group[dataset_name]\n",
    "        print(\"\\n\" + dataset_name + \"\\n\")\n",
    "        print(dataset[:10])  # Print the first 10 elements of the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset \"data\" is what contains the unique molecular identifier values, which are the principal expression quantification schemes used in scRNA-seq analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking through the Neuron dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the datasets within the \"matrix\" group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group name: matrix\n",
      "Datasets within the group:\n",
      "barcodes\n",
      "data\n",
      "features\n",
      "indices\n",
      "indptr\n",
      "shape\n",
      "\n",
      "Dataset: barcodes\n",
      "Shape: (1408818,)\n",
      "dtype: |S45\n",
      "Preview of dataset values:\n",
      "[b'AAACCCAAGAAACCAT-1' b'AAACCCAAGAAACTAC-1' b'AAACCCAAGAAACTCA-1'\n",
      " b'AAACCCAAGAAACTGT-1' b'AAACCCAAGAAATCCA-1' b'AAACCCAAGAAATTGC-1'\n",
      " b'AAACCCAAGAACACCA-1' b'AAACCCAAGAACCTCC-1' b'AAACCCAAGAACTGAT-1'\n",
      " b'AAACCCAAGAACTTCC-1' b'AAACCCAAGAAGATCT-1' b'AAACCCAAGAAGCGAA-1'\n",
      " b'AAACCCAAGAAGCGCT-1' b'AAACCCAAGAAGCTCG-1' b'AAACCCAAGAAGGTAG-1'\n",
      " b'AAACCCAAGAAGTCCG-1' b'AAACCCAAGAATAACC-1' b'AAACCCAAGAATCCCT-1'\n",
      " b'AAACCCAAGAATCTAG-1' b'AAACCCAAGAATTCAG-1' b'AAACCCAAGAATTTGG-1'\n",
      " b'AAACCCAAGACAACCA-1' b'AAACCCAAGACAACTA-1' b'AAACCCAAGACAAGCC-1'\n",
      " b'AAACCCAAGACACACG-1' b'AAACCCAAGACAGTCG-1' b'AAACCCAAGACATACA-1'\n",
      " b'AAACCCAAGACATATG-1' b'AAACCCAAGACATCAA-1' b'AAACCCAAGACATGCG-1'\n",
      " b'AAACCCAAGACCAAGC-1' b'AAACCCAAGACCACGA-1' b'AAACCCAAGACCATAA-1'\n",
      " b'AAACCCAAGACCATGG-1' b'AAACCCAAGACCATTC-1' b'AAACCCAAGACCCTCA-1'\n",
      " b'AAACCCAAGACCGCCT-1' b'AAACCCAAGACCTCCG-1' b'AAACCCAAGACCTGGA-1'\n",
      " b'AAACCCAAGACCTTTG-1' b'AAACCCAAGACGACGT-1' b'AAACCCAAGACGAGCT-1'\n",
      " b'AAACCCAAGACGCCCT-1' b'AAACCCAAGACGCTCC-1' b'AAACCCAAGACGGAAA-1'\n",
      " b'AAACCCAAGACGGATC-1' b'AAACCCAAGACTAAGT-1' b'AAACCCAAGACTACCT-1'\n",
      " b'AAACCCAAGACTACTT-1' b'AAACCCAAGACTAGAT-1']\n",
      "\n",
      "Dataset: data\n",
      "Shape: (35691931,)\n",
      "dtype: int32\n",
      "Preview of dataset values:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "Dataset: indices\n",
      "Shape: (35691931,)\n",
      "dtype: int64\n",
      "Preview of dataset values:\n",
      "[33635  7703  3671 12785 33644 21523 10036 26401  4751  6339   567 28714\n",
      "  6579 26300 19619 27482    67 33637 33641 15116 16081 16852  5498  8687\n",
      " 28681  1395  2203  2494  3991  4281  5747  6018  6409  7163  7168  7742\n",
      "  8198  8752  9056  9196  9470  9692 10358 10703 10831 11295 12237 12271\n",
      " 12824 13795]\n",
      "\n",
      "Dataset: indptr\n",
      "Shape: (1408819,)\n",
      "dtype: int64\n",
      "Preview of dataset values:\n",
      "[   0    1    2    2    2    5    6    7    8    8   10   10   11   12\n",
      "   13   14   16   18   19   21   22   23   23   25  100  102  103  103\n",
      "  104  104  104  105  106  109  110  111  111  113  114  115  188  189\n",
      "  190  191  192  194  195  196 3071 3076]\n",
      "\n",
      "Dataset: shape\n",
      "Shape: (2,)\n",
      "dtype: int32\n",
      "Preview of dataset values:\n",
      "[  33696 1408818]\n"
     ]
    }
   ],
   "source": [
    "# Open the HDF5 file\n",
    "with h5py.File('10k_Mouse_Neurons_3p_nextgem_Multiplex_count_raw_feature_bc_matrix.h5', 'r') as f:\n",
    "    # Specify the group name\n",
    "    group_name = 'matrix'\n",
    "\n",
    "    # Access the group\n",
    "    group = f[group_name]\n",
    "\n",
    "    # Print group attributes\n",
    "    print(\"Group name:\", group_name)\n",
    "    # As it's a group, it won't have a shape attribute\n",
    "    # Add more attributes as needed\n",
    "\n",
    "    # Print the datasets within the group\n",
    "    print(\"Datasets within the group:\")\n",
    "    for dataset_name in group:\n",
    "        print(dataset_name)\n",
    "\n",
    "    # Access and inspect the datasets\n",
    "    for dataset_name in group:\n",
    "        dataset = group[dataset_name]\n",
    "        if isinstance(dataset, h5py.Dataset):\n",
    "            print(\"\\nDataset:\", dataset_name)\n",
    "            print(\"Shape:\", dataset.shape)\n",
    "            print(\"dtype:\", dataset.dtype)\n",
    "            print(\"Preview of dataset values:\")\n",
    "            print(dataset[:50])  # Print the first five rows of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking through the datasets in the \"features\" group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of 'features' subgroup:\n",
      "\n",
      "Datasets within 'features' subgroup:\n",
      "\n",
      "Dataset: _all_tag_keys\n",
      "Shape: (1,)\n",
      "dtype: |S256\n",
      "Preview of dataset values:\n",
      "[b'genome']\n",
      "\n",
      "Dataset: feature_type\n",
      "Shape: (33696,)\n",
      "dtype: |S256\n",
      "Preview of dataset values:\n",
      "[b'Gene Expression' b'Gene Expression' b'Gene Expression'\n",
      " b'Gene Expression' b'Gene Expression' b'Gene Expression'\n",
      " b'Gene Expression' b'Gene Expression' b'Gene Expression'\n",
      " b'Gene Expression']\n",
      "\n",
      "Dataset: genome\n",
      "Shape: (33696,)\n",
      "dtype: |S256\n",
      "Preview of dataset values:\n",
      "[b'GRCm39' b'GRCm39' b'GRCm39' b'GRCm39' b'GRCm39' b'GRCm39' b'GRCm39'\n",
      " b'GRCm39' b'GRCm39' b'GRCm39']\n",
      "\n",
      "Dataset: id\n",
      "Shape: (33696,)\n",
      "dtype: |S256\n",
      "Preview of dataset values:\n",
      "[b'ENSMUSG00000051951' b'ENSMUSG00000089699' b'ENSMUSG00000102331'\n",
      " b'ENSMUSG00000102343' b'ENSMUSG00000025900' b'ENSMUSG00000025902'\n",
      " b'ENSMUSG00000104238' b'ENSMUSG00000104328' b'ENSMUSG00000033845'\n",
      " b'ENSMUSG00000120403']\n",
      "\n",
      "Dataset: name\n",
      "Shape: (33696,)\n",
      "dtype: |S256\n",
      "Preview of dataset values:\n",
      "[b'Xkr4' b'Gm1992' b'Gm19938' b'Gm37381' b'Rp1' b'Sox17' b'Gm37587'\n",
      " b'Gm37323' b'Mrpl15' b'A930006A01Rik']\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('10k_Mouse_Neurons_3p_nextgem_Multiplex_count_raw_feature_bc_matrix.h5', 'r') as f:\n",
    "    # Specify the group name\n",
    "    group_name = 'matrix'\n",
    "\n",
    "    # Access the group\n",
    "    group = f[group_name]\n",
    "\n",
    "    # Check if \"features\" subgroup exists within the \"matrix\" group\n",
    "    features_group = group['features']\n",
    "        \n",
    "    print(\"Attributes of 'features' subgroup:\")\n",
    "    for attr_name, attr_value in features_group.attrs.items():\n",
    "        print(f\"{attr_name}: {attr_value}\")\n",
    "\n",
    "    # You can also check if there are any datasets within the \"features\" subgroup\n",
    "    print(\"\\nDatasets within 'features' subgroup:\")\n",
    "    for dataset_name in features_group:\n",
    "        dataset = features_group[dataset_name]\n",
    "        print(\"\\nDataset:\", dataset_name)\n",
    "        print(\"Shape:\", dataset.shape)\n",
    "        print(\"dtype:\", dataset.dtype)\n",
    "        print(\"Preview of dataset values:\")\n",
    "        print(dataset[:10])  # Print the first five rows of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other ways of data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preprocessing\n",
    "def load_data(file_path):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        # Inspect keys\n",
    "        print(list(f.keys()))\n",
    "        # Load the correct dataset\n",
    "        data = np.array(f['matrix'])\n",
    "    # Perform any necessary preprocessing such as normalization or scaling\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For supervised learning, create the labels and training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way of loading in the data and creating test / train variables.\n",
    "# Load MNIST data\n",
    "f = h5py.File('./train.hdf5', 'r')\n",
    "input_train = f['image'][...]\n",
    "label_train = f['label'][...]\n",
    "f.close()\n",
    "f = h5py.File('./test.hdf5', 'r')\n",
    "input_test = f['image'][...]\n",
    "label_test = f['label'][...]\n",
    "f.close()\n",
    "\n",
    "# Reshape data\n",
    "input_train = input_train.reshape((len(input_train), img_width, img_height, img_num_channels))\n",
    "input_test  = input_test.reshape((len(input_test), img_width, img_height, img_num_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cellranger (from versions: none)\n",
      "ERROR: No matching distribution found for cellranger\n"
     ]
    }
   ],
   "source": [
    "pip install cellranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cellranger'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcellranger\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatrix\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcr_matrix\u001b[39;00m\n\u001b[0;32m      2\u001b[0m filtered_h5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHuman_PBMC_TotalSeqB_3p_nextgem_gemx_nobatchcorrect_count_filtered_feature_bc_matrix.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m filtered_matrix_h5 \u001b[38;5;241m=\u001b[39m cr_matrix\u001b[38;5;241m.\u001b[39mCountMatrix\u001b[38;5;241m.\u001b[39mload_h5_file(filtered_h5)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cellranger'"
     ]
    }
   ],
   "source": [
    "import cellranger.matrix as cr_matrix\n",
    "filtered_h5 = 'Human_PBMC_TotalSeqB_3p_nextgem_gemx_nobatchcorrect_count_filtered_feature_bc_matrix.h5'\n",
    "filtered_matrix_h5 = cr_matrix.CountMatrix.load_h5_file(filtered_h5)\n",
    "\n",
    "\n",
    "import collections\n",
    "import scipy.sparse as sp_sparse\n",
    "import tables\n",
    "\n",
    "CountMatrix = collections.namedtuple('CountMatrix', ['feature_ref', 'barcodes', 'matrix'])\n",
    "\n",
    "def get_matrix_from_h5(filename):\n",
    "    with tables.open_file(filename, 'r') as f:\n",
    "        mat_group = f.get_node(f.root, 'matrix')\n",
    "        barcodes = f.get_node(mat_group, 'barcodes').read()\n",
    "        data = getattr(mat_group, 'data').read()\n",
    "        indices = getattr(mat_group, 'indices').read()\n",
    "        indptr = getattr(mat_group, 'indptr').read()\n",
    "        shape = getattr(mat_group, 'shape').read()\n",
    "        matrix = sp_sparse.csc_matrix((data, indices, indptr), shape=shape)\n",
    "\n",
    "        feature_ref = {}\n",
    "        feature_group = f.get_node(mat_group, 'features')\n",
    "        feature_ids = getattr(feature_group, 'id').read()\n",
    "        feature_names = getattr(feature_group, 'name').read()\n",
    "        feature_types = getattr(feature_group, 'feature_type').read()\n",
    "        feature_ref['id'] = feature_ids\n",
    "        feature_ref['name'] = feature_names\n",
    "        feature_ref['feature_type'] = feature_types\n",
    "        tag_keys = getattr(feature_group, '_all_tag_keys').read()\n",
    "        for key in tag_keys:\n",
    "            feature_ref[key] = getattr(feature_group, key.decode()).read()\n",
    "\n",
    "        return CountMatrix(feature_ref, barcodes, matrix)\n",
    "\n",
    "\n",
    "\n",
    "filtered_h5 = \"/opt/sample345/outs/filtered_feature_bc_matrix.h5\"\n",
    "filtered_matrix_h5 = get_matrix_from_h5(filtered_h5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the GEO files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (13, 0)\t2\n",
      "  (20, 0)\t2\n",
      "  (30, 0)\t1\n",
      "  (34, 0)\t1\n",
      "  (40, 0)\t1\n",
      "  (42, 0)\t5\n",
      "  (50, 0)\t3\n",
      "  (52, 0)\t2\n",
      "  (71, 0)\t1\n",
      "  (123, 0)\t1\n",
      "  (131, 0)\t2\n",
      "  (149, 0)\t1\n",
      "  (175, 0)\t1\n",
      "  (178, 0)\t1\n",
      "  (182, 0)\t2\n",
      "  (189, 0)\t1\n",
      "  (198, 0)\t3\n",
      "  (199, 0)\t1\n",
      "  (206, 0)\t1\n",
      "  (223, 0)\t3\n",
      "  (233, 0)\t2\n",
      "  (234, 0)\t1\n",
      "  (244, 0)\t1\n",
      "  (245, 0)\t2\n",
      "  (248, 0)\t5\n",
      "  :\t:\n",
      "  (31341, 4431)\t6\n",
      "  (31343, 4431)\t1\n",
      "  (31345, 4431)\t1\n",
      "  (31378, 4431)\t2\n",
      "  (31379, 4431)\t1\n",
      "  (31392, 4431)\t18\n",
      "  (31393, 4431)\t3\n",
      "  (31395, 4431)\t4\n",
      "  (31414, 4431)\t3\n",
      "  (31415, 4431)\t2\n",
      "  (31422, 4431)\t1\n",
      "  (31450, 4431)\t19\n",
      "  (31463, 4431)\t7\n",
      "  (32193, 4431)\t12\n",
      "  (32195, 4431)\t18\n",
      "  (32196, 4431)\t19\n",
      "  (32197, 4431)\t102\n",
      "  (32198, 4431)\t56\n",
      "  (32200, 4431)\t61\n",
      "  (32201, 4431)\t74\n",
      "  (32202, 4431)\t3\n",
      "  (32203, 4431)\t1\n",
      "  (32204, 4431)\t17\n",
      "  (32205, 4431)\t1\n",
      "  (32207, 4431)\t36\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mtx file\n",
    "matrix = scipy.io.mmread('matrix.mtx')\n",
    "\n",
    "# Print the matrix\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Input Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deconvolution can be modeled by E = S * C, where:\n",
    "\n",
    "- E is the matrix of bulk tissue level feature representation\n",
    "- S is the matrix of cell-type specific features (signature / reference matrix)\n",
    "- C is the cell-type proportion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Signature Matrix, S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S = feature IDs (genes) * cell type\n",
    "\n",
    "It is a specialized expression matrix of cell type-specific \"barcode\" genes, often called a \"signature matrix\".\n",
    "\n",
    "Each row is a gene, each column is a single-cell transcriptome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Cell-Type Proportion Matrix, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Feature Representation Matrix, E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model's Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Configuration (put towards the beginning later on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "batch_size = 50\n",
    "img_width, img_height, img_num_channels = 28, 28, 1\n",
    "loss_function = sparse_categorical_crossentropy\n",
    "no_classes = 10\n",
    "no_epochs = 25\n",
    "optimizer = Adam()\n",
    "validation_split = 0.2\n",
    "verbosity = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses a max pooling layer. It is a down-sampling operation that reducte the spatial dimensions of the feature maps. Works by partitioning the input feature map into non overlapping rectangles and for each subregion outputs the max value. Used in the encoder portion to reduce spatial dimension but increase depth.\n",
    "\n",
    "The Upsampling Layer, increases the spatial dimensions of the feature maps. It is used to recover the spatial information lost during the downsampling, and produce hihger resolution feature maps (some upsampling techniques include NN-interpolation, bilinear interpolation, transposed convolution). SIMPLE AND COMPUTATIONALLY EFFICIENT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Model Architecture\n",
    "def build_autoencoder(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2), padding='same'),\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2), padding='same'),\n",
    "        layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2), padding='same'),\n",
    "\n",
    "        \n",
    "        layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "        layers.UpSampling2D((2, 2)),\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "        layers.UpSampling2D((2, 2)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.UpSampling2D((2, 2)),\n",
    "        layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden layers are the convolution and pooling.\n",
    "In a convolution we take a filter of a small dimension and move it across an image.\n",
    "The filter's values are tuned iteratively during training.\n",
    "Pooling layers help reduce the amount of parameters, reduce computation.\n",
    "Max pooling selects the maximum value within that pool.\n",
    "\n",
    "\n",
    "The transpose convolution (deconvolution), does the inverse of the convolution operation. It is used to increase the spatial dimensions of feature maps and can be thought of as learning to fill in the missing spatial information. ABLE TO LEARN A SET OF TRAINABLE PARAMETERS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the deconvolutional neural network architecture\n",
    "def create_deconv_nn(input_shape):\n",
    "    model = models.Sequential([\n",
    "        # Encoder\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2), padding='same'),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2), padding='same'),\n",
    "        \n",
    "        # Decoder\n",
    "        layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.UpSampling2D((2, 2)),\n",
    "        layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.UpSampling2D((2, 2)),\n",
    "        layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create the deconvolutional neural network model\n",
    "input_shape = (28, 28, 1)\n",
    "model = create_deconv_nn(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(train_images, train_images, epochs=10, batch_size=128, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model Building and Training\n",
    "input_shape = single_cell_data.shape[1:]\n",
    "autoencoder = build_autoencoder(input_shape)\n",
    "autoencoder.fit(single_cell_data, single_cell_data, epochs=10, batch_size=32, shuffle=True)\n",
    "\n",
    "# Step 5: Model Evaluation (Optional)\n",
    "# Evaluate the trained model using appropriate metrics\n",
    "\n",
    "# Step 6: Deployment (Optional)\n",
    "# Save the trained model for future use\n",
    "#autoencoder.save('single_cell_autoencoder_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(train_images, train_images, epochs=10, batch_size=128, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0640\n",
      "Test loss: 0.06468354910612106\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss = model.evaluate(test_images, test_images)\n",
    "print('Test loss:', test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
